//! Pipeline execution layer extension
#[macro_use]
mod channel;
mod metrics;

use channel::Channel;
use metrics::PipeExecLayerMetrics;

use alloy_consensus::{
    constants::EMPTY_WITHDRAWALS, BlockHeader, Header, Transaction, EMPTY_OMMER_ROOT_HASH,
};
use alloy_eips::{eip4895::Withdrawals, merge::BEACON_NONCE};
use alloy_primitives::{
    map::{HashMap, HashSet},
    Address, TxHash, B256, U256,
};
use gravity_storage::GravityStorage;
use rayon::iter::{IntoParallelIterator, ParallelIterator};
use reth_chain_state::{ExecutedBlockWithTrieUpdates, ExecutedTrieUpdates};
use reth_chainspec::{ChainSpec, EthereumHardforks};
use reth_ethereum_primitives::{Block, BlockBody, Receipt, TransactionSigned};
use reth_evm::{
    parallel_execute::ParallelExecutor, ConfigureEvm, NextBlockEnvAttributes, ParallelDatabase,
};
use reth_evm_ethereum::EthEvmConfig;
use reth_execution_types::{BlockExecutionOutput, ExecutionOutcome};
use reth_primitives::{EthPrimitives, NodePrimitives};
use reth_primitives_traits::{
    proofs::{self},
    Block as _, RecoveredBlock,
};
use reth_provider::{
    OriginalValuesKnown, PersistBlockCache, PERSIST_BLOCK_CACHE, STATE_PROVIDER_OPTS,
};
use std::{
    any::Any,
    collections::BTreeMap,
    sync::{Arc, LazyLock, OnceLock},
    time::Instant,
};
use tokio::sync::{
    mpsc::{UnboundedReceiver, UnboundedSender},
    oneshot, Mutex,
};

use once_cell::sync::Lazy;
use reth_revm::state::AccountInfo;
use reth_trie::{updates::TrieUpdatesV2, HashedPostState, KeccakKeyHasher};
use tracing::*;

static COMPATIBLE_TRIE_OUTPUT: Lazy<bool> = Lazy::new(|| {
    std::env::var("COMPATIBLE_TRIE_OUTPUT").ok().and_then(|v| v.parse().ok()).unwrap_or(false)
});

#[derive(Debug, Clone, Copy)]
pub struct ExecutedBlockMeta {
    /// Which ordered block is used to execute the block
    pub block_id: B256,
    /// Block hash of the executed block
    pub block_hash: B256,
    /// Block number of the executed block
    pub block_number: u64,
}

#[derive(Debug)]
pub struct OrderedBlock {
    /// BlockId of the parent block generated by Gravity SDK
    pub parent_id: B256,
    /// BlockId of the block generated by Gravity SDK
    pub id: B256,
    pub number: u64,
    pub timestamp: u64,
    pub coinbase: Address,
    pub prev_randao: B256,
    pub withdrawals: Withdrawals,
    /// Ordered transactions in the block
    pub transactions: Vec<TransactionSigned>,
    /// Senders of the transactions in the block
    pub senders: Vec<Address>,
}

enum ReceivedBlock {
    /// Block received from Coordinator
    OrderedBlock(OrderedBlock),
    /// History block to be processed. Only used for testing.
    HistoryBlock(RecoveredBlock<Block>),
}

impl ReceivedBlock {
    fn id(&self) -> B256 {
        match self {
            ReceivedBlock::OrderedBlock(block) => block.id,
            ReceivedBlock::HistoryBlock(block) => block.hash(),
        }
    }

    fn parent_id(&self) -> B256 {
        match self {
            ReceivedBlock::OrderedBlock(block) => block.parent_id,
            ReceivedBlock::HistoryBlock(block) => block.parent_hash(),
        }
    }

    fn number(&self) -> u64 {
        match self {
            ReceivedBlock::OrderedBlock(block) => block.number,
            ReceivedBlock::HistoryBlock(block) => block.number(),
        }
    }
}

#[derive(Debug)]
pub enum PipeExecLayerEvent<N: NodePrimitives> {
    /// Make executed block canonical
    MakeCanonical(ExecutedBlockWithTrieUpdates<N>, oneshot::Sender<()>),
}

#[derive(Debug)]
pub struct ExecutionArgs {
    pub block_number_to_block_id: BTreeMap<u64, B256>,
}
/// Owned by EL
#[derive(Debug)]
struct PipeExecService<Storage: GravityStorage> {
    /// Immutable part of the state
    core: Arc<Core<Storage>>,
    /// Receive ordered block from Coordinator
    ordered_block_rx: UnboundedReceiver<ReceivedBlock>,
    /// Receive the execution init args from GravitySDK
    execution_args_rx: oneshot::Receiver<ExecutionArgs>,
}

#[derive(Debug, Clone)]
pub struct TxInfo {
    pub tx_hash: TxHash,
    pub sender: Address,
    pub nonce: u64,
    pub is_discarded: bool,
}

#[derive(Debug, Clone)]
pub struct ExecutionResult {
    pub block_id: B256,
    pub block_number: u64,
    pub block_hash: B256,
    pub txs_info: Vec<TxInfo>,
}

#[derive(Debug)]
struct Core<Storage: GravityStorage> {
    /// Send executed block hash to Coordinator
    execution_result_tx: UnboundedSender<ExecutionResult>,
    /// Receive verified block hash from Coordinator
    verified_block_hash_rx: Arc<Channel<B256 /* block id */, Option<B256> /* block hash */>>,
    storage: Arc<Storage>,
    evm_config: EthEvmConfig,
    chain_spec: Arc<ChainSpec>,
    event_tx: std::sync::mpsc::Sender<PipeExecLayerEvent<EthPrimitives>>,
    execute_block_barrier: Channel<u64 /* block number */, (Header, Instant)>,
    merklize_barrier: Channel<u64 /* block number */, ()>,
    seal_barrier: Channel<u64 /* block number */, B256 /* block hash */>,
    make_canonical_barrier: Channel<u64 /* block number */, Instant>,
    discard_txs_tx: UnboundedSender<Vec<TxHash>>,
    cache: PersistBlockCache,
    metrics: PipeExecLayerMetrics,
}

impl<Storage: GravityStorage> PipeExecService<Storage> {
    async fn run(mut self) {
        self.core.init_storage(self.execution_args_rx.await.unwrap());
        loop {
            let start_time = Instant::now();
            let block = match self.ordered_block_rx.recv().await {
                Some(block) => block,
                None => {
                    self.core.execute_block_barrier.close();
                    self.core.merklize_barrier.close();
                    self.core.make_canonical_barrier.close();
                    return;
                }
            };
            let elapsed = start_time.elapsed();
            self.core.metrics.recv_block_time_diff.record(elapsed);
            info!(target: "PipeExecService.run",
                id=?block.id(),
                parent_id=?block.parent_id(),
                number=?block.number(),
                elapsed=?elapsed,
                "new ordered block"
            );

            let core = self.core.clone();
            tokio::spawn(async move {
                let start_time = Instant::now();
                core.process(block).await;
                core.metrics.process_block_duration.record(start_time.elapsed());
            });
        }
    }
}

const BLOCK_GAS_LIMIT_1G: u64 = 1_000_000_000;

struct ExecuteOrderedBlockResult {
    /// Block without roots and block hash
    block_without_roots: RecoveredBlock<Block>,
    execution_output: BlockExecutionOutput<Receipt>,
    txs_info: Vec<TxInfo>,
}

impl<Storage: GravityStorage> Core<Storage> {
    async fn process(&self, block: ReceivedBlock) {
        let block_number = block.number();
        let block_id = block.id();

        self.storage.insert_block_id(block_number, block_id);
        // Retrieve the parent block header to generate the necessary configs for
        // executing the current block
        let (parent_block_header, prev_start_execute_time) =
            self.execute_block_barrier.wait(block_number - 1).await.unwrap();
        let start_time = Instant::now();
        let ExecuteOrderedBlockResult { block_without_roots, execution_output, txs_info } =
            self.execute_ordered_block(block, &parent_block_header);
        let write_start = Instant::now();
        let change_set = execution_output.state.to_plain_state(OriginalValuesKnown::No);
        self.cache.write_state_changes(block_number, change_set);
        let hashed_state =
            HashedPostState::from_bundle_state::<KeccakKeyHasher>(&execution_output.state.state);
        self.metrics.cache_accout_state.record(write_start.elapsed());
        let elapsed = start_time.elapsed();
        info!(target: "PipeExecService.process",
            block_number=?block_number,
            block_id=?block_id,
            gas_used=execution_output.gas_used,
            elapsed=?elapsed,
            "block executed"
        );
        self.metrics.execute_duration.record(elapsed);
        self.metrics.start_execute_time_diff.record(start_time - prev_start_execute_time);
        self.execute_block_barrier
            .notify(block_number, (block_without_roots.header().clone(), start_time))
            .unwrap();

        let (mut block, senders) = block_without_roots.split();
        let execution_outcome = self.calculate_roots(&mut block, execution_output);

        // Merkling the state trie
        self.merklize_barrier.wait(block_number - 1).await.unwrap();
        let start_time = Instant::now();
        let (state_root, trie_updates, compatible_trie_pudates) =
            self.storage.state_root(&hashed_state, *COMPATIBLE_TRIE_OUTPUT).unwrap();
        let write_start = Instant::now();
        self.cache.write_trie_updates(&trie_updates, block_number);
        self.metrics.cache_trie_state.record(write_start.elapsed());
        let elapsed = start_time.elapsed();
        self.metrics.merklize_duration.record(elapsed);
        self.merklize_barrier.notify(block_number, ()).unwrap();
        info!(target: "PipeExecService.process",
            block_number=?block_number,
            block_id=?block_id,
            state_root=?state_root,
            elapsed=?elapsed,
            "state trie merklized"
        );
        block.header.state_root = state_root;

        // Seal the block
        let parent_hash = self.seal_barrier.wait(block_number - 1).await.unwrap();
        let start_time = Instant::now();
        block.header.parent_hash = parent_hash;
        let sealed_block = block.seal_slow();
        let block_hash = sealed_block.hash();
        self.metrics.seal_duration.record(start_time.elapsed());
        self.seal_barrier.notify(block_number, block_hash).unwrap();
        debug!(target: "PipeExecService.process",
            block_number=?block_number,
            block_id=?block_id,
            block_hash=?block_hash,
            header=?sealed_block.header(),
            "block sealed"
        );

        // Commit the executed block hash to Coordinator
        let start_time = Instant::now();
        self.verify_executed_block_hash(ExecutionResult {
            block_id,
            block_number,
            block_hash,
            txs_info,
        })
        .await
        .unwrap();
        let elapsed = start_time.elapsed();
        self.metrics.verify_duration.record(elapsed);
        info!(target: "PipeExecService.process",
            block_number=?block_number,
            block_id=?block_id,
            block_hash=?block_hash,
            elapsed=?elapsed,
            "block verified"
        );

        let gas_used = sealed_block.gas_used;

        // Make the block canonical
        let prev_finish_commit_time =
            self.make_canonical_barrier.wait(block_number - 1).await.unwrap();
        let start_time = Instant::now();
        let make_canonical = if let Some(compatible_trie_updates) = compatible_trie_pudates {
            self.make_canonical(ExecutedBlockWithTrieUpdates::new(
                Arc::new(RecoveredBlock::new_sealed(sealed_block, senders)),
                Arc::new(execution_outcome),
                Arc::new(hashed_state),
                ExecutedTrieUpdates::Present(Arc::new(compatible_trie_updates)),
                Arc::new(trie_updates),
            ))
        } else {
            self.make_canonical(ExecutedBlockWithTrieUpdates::new(
                Arc::new(RecoveredBlock::new_sealed(sealed_block, senders)),
                Arc::new(execution_outcome),
                Default::default(),
                ExecutedTrieUpdates::empty(),
                Arc::new(trie_updates),
            ))
        };
        make_canonical.await;
        self.storage.update_canonical(block_number, block_hash);
        let elapsed = start_time.elapsed();
        info!(target: "PipeExecService.process",
            block_number=?block_number,
            block_id=?block_id,
            block_hash=?block_hash,
            elapsed=?elapsed,
            "block made canonical"
        );
        let finish_commit_time = Instant::now();
        self.metrics.make_canonical_duration.record(elapsed);
        self.metrics.finish_commit_time_diff.record(finish_commit_time - prev_finish_commit_time);
        self.make_canonical_barrier.notify(block_number, finish_commit_time).unwrap();

        self.metrics.total_gas_used.increment(gas_used);
    }

    /// Push executed block hash to Coordinator and wait for verification result from Coordinator.
    /// Returns `None` if the channel has been closed.
    async fn verify_executed_block_hash(&self, execution_result: ExecutionResult) -> Option<()> {
        let block_id = execution_result.block_id;
        let executed_block_hash = execution_result.block_hash;
        self.execution_result_tx.send(execution_result).ok()?;
        let block_hash = self.verified_block_hash_rx.wait(block_id).await?;
        if let Some(block_hash) = block_hash {
            assert_eq!(executed_block_hash, block_hash);
        }
        Some(())
    }

    fn create_block_for_executor(
        &self,
        ordered_block: OrderedBlock,
        parent_header: &Header,
        state: &Storage::StateView,
    ) -> (RecoveredBlock<Block>, Vec<TxInfo>) {
        assert_eq!(ordered_block.transactions.len(), ordered_block.senders.len());

        let evm_env = self
            .evm_config
            .next_evm_env(
                parent_header,
                &NextBlockEnvAttributes {
                    timestamp: ordered_block.timestamp,
                    suggested_fee_recipient: ordered_block.coinbase,
                    prev_randao: ordered_block.prev_randao,
                    gas_limit: BLOCK_GAS_LIMIT_1G,
                    parent_beacon_block_root: Some(ordered_block.parent_id),
                    withdrawals: Some(ordered_block.withdrawals.clone()),
                },
            )
            .unwrap();

        let mut block = Block {
            header: Header {
                beneficiary: ordered_block.coinbase,
                timestamp: ordered_block.timestamp,
                mix_hash: ordered_block.prev_randao,
                base_fee_per_gas: Some(evm_env.block_env.basefee),
                number: ordered_block.number,
                gas_limit: BLOCK_GAS_LIMIT_1G,
                ommers_hash: EMPTY_OMMER_ROOT_HASH,
                nonce: BEACON_NONCE.into(),
                ..Default::default()
            },
            body: BlockBody::default(),
        };

        if self.chain_spec.is_shanghai_active_at_timestamp(block.timestamp) {
            if ordered_block.withdrawals.is_empty() {
                block.header.withdrawals_root = Some(EMPTY_WITHDRAWALS);
                block.body.withdrawals = Some(Withdrawals::default());
            } else {
                block.header.withdrawals_root =
                    Some(proofs::calculate_withdrawals_root(&ordered_block.withdrawals));
                block.body.withdrawals = Some(ordered_block.withdrawals);
            }
        }

        // only determine cancun fields when active
        if self.chain_spec.is_cancun_active_at_timestamp(block.timestamp) {
            // FIXME: Is it OK to use the parent's block id as `parent_beacon_block_root` before
            // execution?
            block.header.parent_beacon_block_root = Some(ordered_block.parent_id);

            // TODO(nekomoto): fill `excess_blob_gas` and `blob_gas_used` fields
            block.header.excess_blob_gas = Some(0);
            block.header.blob_gas_used = Some(0);
        }

        // Discard the invalid txs
        let start_time = Instant::now();
        let (txs, senders, txs_info) = self.filter_invalid_txs(
            &state,
            ordered_block.transactions,
            ordered_block.senders,
            evm_env.block_env.basefee,
        );
        self.metrics.filter_transaction_duration.record(start_time.elapsed());

        block.body.transactions = txs;
        (RecoveredBlock::new_unhashed(block, senders), txs_info)
    }

    fn execute_ordered_block(
        &self,
        block: ReceivedBlock,
        parent_header: &Header,
    ) -> ExecuteOrderedBlockResult {
        let block_id = block.id();
        let parent_id = block.parent_id();
        let block_number = block.number();
        let state = self.storage.get_state_view(STATE_PROVIDER_OPTS.clone()).unwrap();

        let (block, txs_info) = match block {
            ReceivedBlock::OrderedBlock(ordered_block) => {
                self.create_block_for_executor(ordered_block, parent_header, &state)
            }
            ReceivedBlock::HistoryBlock(block) => (block, Vec::new()),
        };

        info!(target: "execute_ordered_block",
            id=?block_id,
            parent_id=?parent_id,
            number=?block_number,
            "ready to execute block"
        );

        let mut executor = self.evm_config.parallel_executor(state);
        let outcome = executor.execute(&block).unwrap_or_else(|err| {
            serde_json::to_writer(
                std::io::BufWriter::new(
                    std::fs::File::create(format!("{}.json", block_id)).unwrap(),
                ),
                &block,
            )
            .unwrap();
            panic!("failed to execute block {:?}: {:?}", block_id, err)
        });

        ExecuteOrderedBlockResult {
            block_without_roots: block,
            execution_output: outcome,
            txs_info,
        }
    }

    /// Calculate the receipts root, logs bloom, and transactions root, etc. and fill them into the
    /// block header.
    fn calculate_roots(
        &self,
        block: &mut Block,
        execution_output: BlockExecutionOutput<Receipt>,
    ) -> ExecutionOutcome {
        block.header.gas_used = execution_output.gas_used;

        // only determine cancun fields when active
        if self.chain_spec.is_prague_active_at_timestamp(block.timestamp) {
            block.header.requests_hash = Some(execution_output.requests.requests_hash());
        }

        let execution_outcome = ExecutionOutcome::new(
            execution_output.state,
            vec![execution_output.result.receipts],
            block.number,
            vec![execution_output.result.requests.into()],
        );

        // Fill the block header with the calculated values
        block.header.transactions_root =
            proofs::calculate_transaction_root(&block.body.transactions);
        if self.chain_spec.is_byzantium_active_at_block(block.number()) {
            block.header.receipts_root =
                execution_outcome.ethereum_receipts_root(block.number).unwrap();
            block.header.logs_bloom = execution_outcome.block_logs_bloom(block.number).unwrap();
        }

        execution_outcome
    }

    async fn make_canonical(&self, executed_block: ExecutedBlockWithTrieUpdates) {
        // Make executed block canonical
        let (tx, rx) = oneshot::channel();
        self.event_tx.send(PipeExecLayerEvent::MakeCanonical(executed_block, tx)).unwrap();
        rx.await.unwrap();
    }

    fn init_storage(&self, execution_args: ExecutionArgs) {
        execution_args.block_number_to_block_id.into_iter().for_each(|(block_number, block_id)| {
            self.storage.insert_block_id(block_number, block_id);
        });
    }

    /// Return the filtered valid transactions with sender without changing the relative order of
    /// the transactions.
    fn filter_invalid_txs(
        &self,
        db: &Storage::StateView,
        txs: Vec<TransactionSigned>,
        senders: Vec<Address>,
        base_fee_per_gas: u64,
    ) -> (Vec<TransactionSigned>, Vec<Address>, Vec<TxInfo>) {
        let invalid_idxs = filter_invalid_txs(db, &txs, &senders, base_fee_per_gas);
        if !invalid_idxs.is_empty() {
            let _ = self
                .discard_txs_tx
                .send(invalid_idxs.iter().map(|&idx| txs[idx].hash()).cloned().collect::<Vec<_>>());

            let mut filtered_txs = Vec::with_capacity(txs.len() - invalid_idxs.len());
            let mut filtered_senders = Vec::with_capacity(filtered_txs.capacity());
            let mut txs_info = Vec::with_capacity(txs.len());
            for (i, (tx, sender)) in txs.into_iter().zip(senders.into_iter()).enumerate() {
                if invalid_idxs.contains(&i) {
                    txs_info.push(TxInfo {
                        tx_hash: *tx.hash(),
                        sender,
                        nonce: tx.nonce(),
                        is_discarded: true,
                    });
                    continue;
                }

                txs_info.push(TxInfo {
                    tx_hash: *tx.hash(),
                    sender,
                    nonce: tx.nonce(),
                    is_discarded: false,
                });
                filtered_txs.push(tx);
                filtered_senders.push(sender);
            }
            (filtered_txs, filtered_senders, txs_info)
        } else {
            let mut txs_info = Vec::with_capacity(txs.len());
            for (tx, sender) in txs.iter().zip(senders.iter()) {
                txs_info.push(TxInfo {
                    tx_hash: *tx.hash(),
                    sender: *sender,
                    nonce: tx.nonce(),
                    is_discarded: false,
                });
            }
            (txs, senders, txs_info)
        }
    }
}

/// Return the invalid transaction indexes.
fn filter_invalid_txs<DB: ParallelDatabase>(
    db: DB,
    txs: &Vec<TransactionSigned>,
    senders: &Vec<Address>,
    base_fee_per_gas: u64,
) -> HashSet<usize> {
    let mut sender_idx: HashMap<&Address, Vec<usize>> = HashMap::default();
    for (i, sender) in senders.iter().enumerate() {
        sender_idx.entry(sender).or_insert_with(Vec::new).push(i);
    }

    let is_tx_valid = |tx: &TransactionSigned, sender: &Address, account: &mut AccountInfo| {
        if account.nonce != tx.nonce() {
            warn!(target: "filter_invalid_txs",
                tx_hash=?tx.hash(),
                sender=?sender,
                nonce=?tx.nonce(),
                account_nonce=?account.nonce,
                "nonce mismatch"
            );
            return false;
        }
        let gas_spent = U256::from(tx.effective_gas_price(Some(base_fee_per_gas)))
            .saturating_mul(U256::from(tx.gas_limit()))
            .saturating_add(tx.value());
        if account.balance < gas_spent {
            warn!(target: "filter_invalid_txs",
                tx_hash=?tx.hash(),
                sender=?sender,
                balance=?account.balance,
                gas_spent=?gas_spent,
                "insufficient balance"
            );
            return false;
        }
        account.balance -= gas_spent;
        account.nonce += 1;
        true
    };

    sender_idx
        .into_par_iter()
        .flat_map(|(sender, idxs)| {
            if let Some(mut account) = db.basic_ref(*sender).unwrap() {
                idxs.into_iter()
                    .filter(|&idx| !is_tx_valid(&txs[idx], sender, &mut account))
                    .collect()
            } else {
                // Sender does not exist in the state trie, balance is 0
                warn!(target: "filter_invalid_txs",
                    tx_hash=?txs[idxs[0]].hash(),
                    sender=?sender,
                    "insufficient balance"
                );
                idxs
            }
        })
        .collect::<HashSet<_>>()
}

/// Called by Coordinator
#[derive(Debug)]
pub struct PipeExecLayerApi<Storage> {
    ordered_block_tx: UnboundedSender<ReceivedBlock>,
    execution_result_rx: Mutex<UnboundedReceiver<ExecutionResult>>,
    verified_block_hash_tx: Arc<Channel<B256 /* block id */, Option<B256> /* block hash */>>,
    storage: Arc<Storage>,
}

impl<Storage: GravityStorage> PipeExecLayerApi<Storage> {
    /// Push ordered block to EL for execution.
    /// Returns `None` if the channel has been closed.
    pub fn push_ordered_block(&self, block: OrderedBlock) -> Option<()> {
        self.ordered_block_tx.send(ReceivedBlock::OrderedBlock(block)).ok()
    }

    /// Only used for testing.
    pub fn push_history_block(&self, block: RecoveredBlock<Block>) -> Option<()> {
        self.ordered_block_tx.send(ReceivedBlock::HistoryBlock(block)).ok()
    }

    /// Pull executed block hash from EL for verification.
    /// Returns `None` if the channel has been closed.
    pub async fn pull_executed_block_hash(&self) -> Option<ExecutionResult> {
        self.execution_result_rx.lock().await.recv().await
    }

    /// Push verified block hash to EL for commit.
    /// The caller can optionally pass in a verified block hash, which is solely used for the EL
    /// defensive check to ensure the consistency of the block hash before and after verification.
    /// Returns `None` if the channel has been closed.
    pub fn commit_executed_block_hash(
        &self,
        block_id: B256,
        block_hash: Option<B256>,
    ) -> Option<()> {
        self.verified_block_hash_tx.notify(block_id, block_hash)
    }

    /// Get the block id by block number.
    pub fn get_block_id(&self, block_number: u64) -> Option<B256> {
        self.storage.get_block_id(block_number)
    }
}

impl<Storage> Drop for PipeExecLayerApi<Storage> {
    fn drop(&mut self) {
        self.verified_block_hash_tx.close();
    }
}

/// Called by EL.
#[derive(Debug)]
pub struct PipeExecLayerExt<N: NodePrimitives> {
    /// Receive events from PipeExecService
    pub event_rx: std::sync::Mutex<Option<std::sync::mpsc::Receiver<PipeExecLayerEvent<N>>>>,
    /// Receive discarded txs from PipeExecService
    pub discard_txs: tokio::sync::Mutex<Option<UnboundedReceiver<Vec<TxHash>>>>,
}

/// A static instance of `PipeExecLayerExt` used for dispatching events.
pub static PIPE_EXEC_LAYER_EXT: OnceLock<Box<dyn Any + Send + Sync>> = OnceLock::new();

pub fn get_pipe_exec_layer_ext<N: NodePrimitives>() -> Option<&'static PipeExecLayerExt<N>> {
    PIPE_EXEC_LAYER_EXT.get().map(|ext| ext.downcast_ref::<PipeExecLayerExt<N>>().unwrap())
}

/// Whether to validate the block before inserting it into `TreeState`.
pub static PIPE_VALIDATE_BLOCK_BEFORE_INSERT: LazyLock<bool> =
    LazyLock::new(|| std::env::var("PIPE_VALIDATE_BLOCK_BEFORE_INSERT").is_ok());

/// Create a new `PipeExecLayerApi` instance and launch a `PipeExecService`.
pub fn new_pipe_exec_layer_api<Storage: GravityStorage>(
    chain_spec: Arc<ChainSpec>,
    storage: Storage,
    latest_block_header: Header,
    latest_block_hash: B256,
    execution_args_rx: oneshot::Receiver<ExecutionArgs>,
) -> PipeExecLayerApi<Storage> {
    let (ordered_block_tx, ordered_block_rx) = tokio::sync::mpsc::unbounded_channel();
    let (execution_result_tx, execution_result_rx) = tokio::sync::mpsc::unbounded_channel();
    let verified_block_hash_ch = Arc::new(Channel::new());
    let (event_tx, event_rx) = std::sync::mpsc::channel();
    let (discard_txs_tx, discard_txs_rx) = tokio::sync::mpsc::unbounded_channel();

    let storage = Arc::new(storage);

    let latest_block_number = latest_block_header.number;
    let start_time = Instant::now();
    let service = PipeExecService {
        core: Arc::new(Core {
            execution_result_tx,
            verified_block_hash_rx: verified_block_hash_ch.clone(),
            storage: storage.clone(),
            evm_config: EthEvmConfig::new(chain_spec.clone()),
            chain_spec,
            event_tx,
            execute_block_barrier: Channel::new_with_states([(
                latest_block_number,
                (latest_block_header, start_time),
            )]),
            merklize_barrier: Channel::new_with_states([(latest_block_number, ())]),
            seal_barrier: Channel::new_with_states([(latest_block_number, latest_block_hash)]),
            make_canonical_barrier: Channel::new_with_states([(latest_block_number, start_time)]),
            discard_txs_tx,
            cache: PERSIST_BLOCK_CACHE.clone(),
            metrics: PipeExecLayerMetrics::default(),
        }),
        ordered_block_rx,
        execution_args_rx,
    };
    tokio::spawn(service.run());

    PIPE_EXEC_LAYER_EXT.get_or_init(|| {
        Box::new(PipeExecLayerExt {
            event_rx: std::sync::Mutex::new(Some(event_rx)),
            discard_txs: tokio::sync::Mutex::new(Some(discard_txs_rx)),
        })
    });

    PipeExecLayerApi {
        ordered_block_tx,
        execution_result_rx: Mutex::new(execution_result_rx),
        verified_block_hash_tx: verified_block_hash_ch,
        storage,
    }
}
